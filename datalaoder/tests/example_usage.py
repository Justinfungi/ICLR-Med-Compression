"""
ACDCæ•°æ®é›†ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ACDCæ•°æ®åŠ è½½å™¨è¿›è¡Œä¸åŒä»»åŠ¡
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import os
from datetime import datetime
from typing import Dict, Any
import warnings

# æŠ‘åˆ¶æ‰€æœ‰è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore", category=UserWarning)  # æŠ‘åˆ¶ç”¨æˆ·è­¦å‘Š
warnings.filterwarnings("ignore", module="SimpleITK")    # æŠ‘åˆ¶SimpleITKè­¦å‘Š
warnings.filterwarnings("ignore")  # æŠ‘åˆ¶æ‰€æœ‰å…¶ä»–è­¦å‘Š

# å°è¯•æŠ‘åˆ¶SimpleITKçš„C++å±‚é¢è­¦å‘Š
import os
import sys
os.environ['SITK_SHOW_COMMAND'] = ''  # æŠ‘åˆ¶SimpleITKæ˜¾ç¤ºå‘½ä»¤
os.environ['ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS'] = '1'  # è®¾ç½®ITKçº¿ç¨‹æ•°

# é‡å®šå‘stderrä»¥æŠ‘åˆ¶C++å±‚é¢çš„è­¦å‘Šï¼ˆä»…é’ˆå¯¹SimpleITKè­¦å‘Šï¼‰
class SuppressSTDERR:
    def __enter__(self):
        self._stderr = sys.stderr
        sys.stderr = open(os.devnull, 'w')
        return self
    
    def __exit__(self, *args):
        sys.stderr.close()
        sys.stderr = self._stderr

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
import sys
sys.path.append(str(Path(__file__).parent.parent))

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from acdc_dataset import ACDCDataset, ACDCDataModule
from utils.transforms import get_train_transforms, get_val_transforms
from utils.analysis import analyze_dataset_statistics, create_dataset_report
from utils.metrics import calculate_cardiac_metrics
from utils.visualization import visualize_cardiac_phases


def create_output_directory(sub_dir: str = "") -> Path:
    """åˆ›å»ºè¾“å‡ºç›®å½•"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_dir = Path("output") / f"acdc_results_{timestamp}"
    
    if sub_dir:
        output_dir = base_dir / sub_dir
    else:
        output_dir = base_dir
    
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    return output_dir


def example_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸš€ ACDCæ•°æ®é›†åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = create_output_directory("basic_usage")
    
    # æ•°æ®è·¯å¾„
    data_root = "/Users/fenghaojie/Documents/ICLR/MedCompression/acdc_dataset"
    
    # åˆ›å»ºæ•°æ®é›† - æŠ‘åˆ¶SimpleITKè­¦å‘Š
    with SuppressSTDERR():
    dataset = ACDCDataset(
        data_root=data_root,
        split='training',
        mode='3d_keyframes',  # åŠ è½½EDå’ŒESå…³é”®å¸§
        load_segmentation=True,
        normalize=True
    )
    
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ: {len(dataset)}ä¾‹æ‚£è€…")
    
    # è·å–ä¸€ä¸ªæ ·æœ¬ - æŠ‘åˆ¶SimpleITKè­¦å‘Š
    with SuppressSTDERR():
    sample = dataset[0]
    print(f"\nğŸ“Š æ ·æœ¬ä¿¡æ¯:")
    for key, value in sample.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key}: {value.shape} ({value.dtype})")
        elif isinstance(value, dict):
            print(f"  {key}: {list(value.keys())}")
        else:
            print(f"  {key}: {value}")
    
    # å¯è§†åŒ–æ ·æœ¬å¹¶ä¿å­˜
    if 'images' in sample:
        print(f"\nğŸ–¼ï¸ å¯è§†åŒ–å¿ƒè„æ—¶ç›¸...")
        save_path = output_dir / f"cardiac_phases_{sample.get('patient_id', 'unknown')}.png"
        # ç›´æ¥ä¿å­˜ï¼Œä¸æ˜¾ç¤º
        try:
            # è®¾ç½®matplotlibä¸ºéäº¤äº’æ¨¡å¼
            plt.ioff()
            
            # åˆ›å»ºå¿ƒè„æ—¶ç›¸å¯è§†åŒ–
            images = sample['images']
            segmentations = sample.get('segmentations', None)
            
            if isinstance(images, torch.Tensor):
                images = images.numpy()
            if segmentations is not None and isinstance(segmentations, torch.Tensor):
                segmentations = segmentations.numpy()
            
            # é€‰æ‹©ä¸­é—´åˆ‡ç‰‡
            slice_idx = images.shape[1] // 2
            
            # åˆ›å»ºå­å›¾
            n_cols = 4 if segmentations is not None else 2
            fig, axes = plt.subplots(1, n_cols, figsize=(4*n_cols, 4))
            
            if n_cols == 2:
                axes = [axes[0], None, axes[1], None]
            
            # æ˜¾ç¤ºEDç›¸
            ed_img = images[0, slice_idx]
            axes[0].imshow(ed_img, cmap='gray')
            axes[0].set_title('ED (End-Diastolic)')
            axes[0].axis('off')
            
            if segmentations is not None:
                ed_seg = segmentations[0, slice_idx]
                axes[1].imshow(ed_seg, cmap='viridis')
                axes[1].set_title('ED Segmentation')
                axes[1].axis('off')
            
            # æ˜¾ç¤ºESç›¸
            es_img = images[1, slice_idx]
            axes[2].imshow(es_img, cmap='gray')
            axes[2].set_title('ES (End-Systolic)')
            axes[2].axis('off')
            
            if segmentations is not None:
                es_seg = segmentations[1, slice_idx]
                axes[3].imshow(es_seg, cmap='viridis')
                axes[3].set_title('ES Segmentation')
                axes[3].axis('off')
            
            # æ·»åŠ æ‚£è€…ä¿¡æ¯
            patient_info = sample.get('patient_info', {})
            disease = patient_info.get('Group', 'Unknown')
            plt.suptitle(f'Patient: {sample.get("patient_id", "Unknown")} | Disease: {disease} | Slice: {slice_idx}', 
                         fontsize=12)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾åƒ
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"ğŸ’¾ å¿ƒè„æ—¶ç›¸å›¾åƒå·²ä¿å­˜: {save_path}")
            
        except Exception as e:
            print(f"âš ï¸ å¯è§†åŒ–ä¿å­˜å¤±è´¥: {e}")
    
    return dataset


def example_data_module():
    """æ•°æ®æ¨¡å—ä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ”„ ACDCæ•°æ®æ¨¡å—ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    data_root = "/Users/fenghaojie/Documents/ICLR/MedCompression/acdc_dataset"
    
    # åˆ›å»ºæ•°æ®æ¨¡å— - ä½¿ç”¨æ›´ä¿å®ˆçš„è®¾ç½®
    data_module = ACDCDataModule(
        data_root=data_root,
        batch_size=1,  # ä½¿ç”¨batch_size=1é¿å…æ‰¹å¤„ç†é—®é¢˜
        num_workers=0,  # ä½¿ç”¨å•è¿›ç¨‹é¿å…å¤šè¿›ç¨‹é—®é¢˜
        mode='3d_keyframes',
        target_spacing=(1.5, 1.5, 10.0),  # é‡é‡‡æ ·åˆ°ç»Ÿä¸€åˆ†è¾¨ç‡
        normalize=True
    )
    
    # è®¾ç½®æ•°æ®é›†
    data_module.setup()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = data_module.get_statistics()
    print(f"ğŸ“Š æ•°æ®æ¨¡å—ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # è·å–æ•°æ®åŠ è½½å™¨
    train_loader = data_module.train_dataloader()
    
    # æµ‹è¯•æ‰¹é‡åŠ è½½
    print(f"\nğŸ”„ æµ‹è¯•æ‰¹é‡æ•°æ®åŠ è½½:")
    for i, batch in enumerate(train_loader):
        print(f"Batch {i}:")
        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: {value.shape}")
            else:
                print(f"  {key}: {type(value)}")
        
        if i >= 1:  # åªæµ‹è¯•å‰ä¸¤ä¸ªbatch
            break
    
    return data_module


def example_with_transforms():
    """æ•°æ®å˜æ¢ä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ¨ æ•°æ®å˜æ¢ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    data_root = "/Users/fenghaojie/Documents/ICLR/MedCompression/acdc_dataset"
    
    # åˆ›å»ºå¸¦å˜æ¢çš„æ•°æ®é›†
    train_transforms = get_train_transforms(
        output_size=(8, 224, 224),  # ç»Ÿä¸€è¾“å‡ºå°ºå¯¸
        augmentation=True
    )
    
    dataset = ACDCDataset(
        data_root=data_root,
        split='training',
        mode='3d_keyframes',
        transform=train_transforms,
        normalize=True
    )
    
    # è·å–åŸå§‹å’Œå˜æ¢åçš„æ ·æœ¬
    sample = dataset[0]
    
    print(f"ğŸ”„ å˜æ¢åçš„æ ·æœ¬:")
    for key, value in sample.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key}: {value.shape} ({value.dtype})")
    
    return dataset


def example_4d_sequence():
    """4Dæ—¶åºæ•°æ®ä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ¬ 4Dæ—¶åºæ•°æ®ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = create_output_directory("4d_sequence")
    
    data_root = "/Users/fenghaojie/Documents/ICLR/MedCompression/acdc_dataset"
    
    # åˆ›å»º4Dæ•°æ®é›†
    dataset = ACDCDataset(
        data_root=data_root,
        split='training',
        mode='4d_sequence',  # åŠ è½½å®Œæ•´4Dåºåˆ—
        load_segmentation=False,  # 4Dæ•°æ®é€šå¸¸æ²¡æœ‰å®Œæ•´åˆ†å‰²æ ‡æ³¨
        normalize=True
    )
    
    print(f"âœ… 4Dæ•°æ®é›†: {len(dataset)}ä¾‹æ‚£è€…")
    
    # è·å–4Dæ ·æœ¬
    sample = dataset[0]
    
    if 'image' in sample:
        print(f"ğŸ“¹ 4Då›¾åƒå½¢çŠ¶: {sample['image'].shape}")  # (T, Z, H, W)
        print(f"ğŸ“Š æ—¶é—´å¸§æ•°: {sample['image'].shape[0]}")
        print(f"ğŸ“ ç©ºé—´å°ºå¯¸: {sample['image'].shape[1:]}")
        
        # åˆ›å»ºå¿ƒè·³åŠ¨ç”»å¹¶ä¿å­˜
        patient_id = sample.get('patient_id', 'unknown')
        animation_path = output_dir / f"cardiac_animation_{patient_id}.gif"
        create_cardiac_animation(sample['image'], save_path=str(animation_path), create_video=True)
    
    return dataset


def create_cardiac_animation(image_4d: torch.Tensor, save_path: str = None, create_video: bool = True):
    """åˆ›å»ºå¿ƒè·³åŠ¨ç”»"""
    print(f"ğŸ¬ åˆ›å»ºå¿ƒè·³åŠ¨ç”»...")
    
    # è®¾ç½®matplotlibä¸ºéäº¤äº’æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºå›¾å½¢
    plt.ioff()
    
    # è½¬æ¢ä¸ºnumpy
    if isinstance(image_4d, torch.Tensor):
        image_4d = image_4d.numpy()
    
    # é€‰æ‹©ä¸­é—´åˆ‡ç‰‡
    middle_slice = image_4d.shape[1] // 2
    
    # æ˜¾ç¤ºå‡ ä¸ªå…³é”®å¸§
    n_frames = min(8, image_4d.shape[0])
    frame_indices = np.linspace(0, image_4d.shape[0]-1, n_frames, dtype=int)
    
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    axes = axes.flatten()
    
    for i, frame_idx in enumerate(frame_indices):
        axes[i].imshow(image_4d[frame_idx, middle_slice], cmap='gray')
        axes[i].set_title(f'Frame {frame_idx+1}')
        axes[i].axis('off')
    
    plt.suptitle('Cardiac Cycle Key Frames', fontsize=14)
    plt.tight_layout()
    
    # ä¿å­˜å…³é”®å¸§å›¾åƒ
    if save_path:
        frames_path = save_path.replace('.gif', '_frames.png')
        plt.savefig(frames_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ å¿ƒè·³å…³é”®å¸§å·²ä¿å­˜: {frames_path}")
    
    plt.close()  # å…³é—­å›¾å½¢ä»¥èŠ‚çœå†…å­˜
    
    # åˆ›å»ºåŠ¨ç”»è§†é¢‘
    if create_video and save_path:
        try:
            import imageio
            
            # å‡†å¤‡æ‰€æœ‰å¸§
            frames = []
            for t in range(image_4d.shape[0]):
                frame = image_4d[t, middle_slice]
                # å½’ä¸€åŒ–åˆ°0-255
                frame_norm = ((frame - frame.min()) / (frame.max() - frame.min()) * 255).astype(np.uint8)
                frames.append(frame_norm)
            
            # ä¿å­˜ä¸ºGIF
            gif_path = save_path.replace('.png', '.gif')
            imageio.mimsave(gif_path, frames, duration=0.2, loop=0)
            print(f"ğŸ¬ å¿ƒè·³åŠ¨ç”»GIFå·²ä¿å­˜: {gif_path}")
            
        except ImportError:
            print("âš ï¸ éœ€è¦å®‰è£…imageioæ¥ç”ŸæˆGIF: pip install imageio")
        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºGIFå¤±è´¥: {e}")
    
    return frames_path if save_path else None


def example_cardiac_metrics():
    """å¿ƒè„åŠŸèƒ½æŒ‡æ ‡è®¡ç®—ç¤ºä¾‹"""
    print("\nğŸ’“ å¿ƒè„åŠŸèƒ½æŒ‡æ ‡è®¡ç®—ç¤ºä¾‹")
    print("=" * 50)
    
    data_root = "/Users/fenghaojie/Documents/ICLR/MedCompression/acdc_dataset"
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = ACDCDataset(
        data_root=data_root,
        split='training',
        mode='3d_keyframes',
        load_segmentation=True
    )
    
    # è·å–æ ·æœ¬
    sample = dataset[0]
    
    if 'segmentations' in sample and sample['segmentations'] is not None:
        # è·å–EDå’ŒESåˆ†å‰²å›¾
        ed_seg = sample['segmentations'][0].numpy()  # ED
        es_seg = sample['segmentations'][1].numpy()  # ES
        
        # è·å–ä½“ç´ é—´è·
        spacing = sample['metadata'].get('spacing', (1.5625, 1.5625, 10.0))
        
        # è®¡ç®—å¿ƒè„åŠŸèƒ½æŒ‡æ ‡
        metrics = calculate_cardiac_metrics(ed_seg, es_seg, spacing)
        
        print(f"ğŸ“Š æ‚£è€… {sample['patient_id']} å¿ƒè„åŠŸèƒ½æŒ‡æ ‡:")
        print(f"  ç–¾ç—…ç±»å‹: {sample['patient_info'].get('Group', 'Unknown')}")
        print(f"  å·¦å¿ƒå®¤èˆ’å¼ æœ«æœŸå®¹ç§¯ (LVEDV): {metrics['lv_edv']:.1f} ml")
        print(f"  å·¦å¿ƒå®¤æ”¶ç¼©æœ«æœŸå®¹ç§¯ (LVESV): {metrics['lv_esv']:.1f} ml")
        print(f"  å·¦å¿ƒå®¤æ¯æé‡ (LVSV): {metrics['lv_sv']:.1f} ml")
        print(f"  å·¦å¿ƒå®¤å°„è¡€åˆ†æ•° (LVEF): {metrics['lv_ef']:.1f} %")
        print(f"  å³å¿ƒå®¤å°„è¡€åˆ†æ•° (RVEF): {metrics['rv_ef']:.1f} %")
        print(f"  å·¦å¿ƒå®¤å¿ƒè‚Œè´¨é‡: {metrics['lv_myocardium_mass']:.1f} g")
        
        # åˆ¤æ–­å¿ƒåŠŸèƒ½çŠ¶æ€
        if metrics['lv_ef'] >= 50:
            status = "æ­£å¸¸"
        elif metrics['lv_ef'] >= 40:
            status = "è½»åº¦å‡ä½"
        elif metrics['lv_ef'] >= 30:
            status = "ä¸­åº¦å‡ä½"
        else:
            status = "é‡åº¦å‡ä½"
        
        print(f"  ğŸ’“ å¿ƒåŠŸèƒ½è¯„ä¼°: {status}")


def example_dataset_analysis():
    """æ•°æ®é›†åˆ†æç¤ºä¾‹"""
    print("\nğŸ“ˆ æ•°æ®é›†åˆ†æç¤ºä¾‹")
    print("=" * 50)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = create_output_directory("dataset_analysis")
    
    data_root = "/Users/fenghaojie/Documents/ICLR/MedCompression/acdc_dataset"
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = ACDCDataset(
        data_root=data_root,
        split='training',
        mode='3d_keyframes'
    )
    
    # åˆ†æç»Ÿè®¡ä¿¡æ¯
    stats = analyze_dataset_statistics(dataset)
    
    print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡åˆ†æ:")
    print(f"  æ€»æ‚£è€…æ•°: {stats['total_patients']}")
    print(f"  ç–¾ç—…åˆ†å¸ƒ: {stats['disease_distribution']}")
    
    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Šå¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•
    create_dataset_report(dataset, output_dir)
    
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: {output_dir}")
    
    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    try:
        from utils.visualization import plot_disease_distribution, plot_patient_demographics
        
        # ç–¾ç—…åˆ†å¸ƒå›¾
        disease_plot_path = output_dir / "disease_distribution.png"
        plot_disease_distribution(stats['disease_distribution'], save_path=disease_plot_path)
        print(f"ğŸ“Š ç–¾ç—…åˆ†å¸ƒå›¾å·²ä¿å­˜: {disease_plot_path}")
        
        # æ‚£è€…ç»Ÿè®¡å›¾
        if 'patient_demographics' in stats and stats['patient_demographics']:
            demo_plot_path = output_dir / "patient_demographics.png"
            plot_patient_demographics(stats, save_path=demo_plot_path)
            print(f"ğŸ‘¥ æ‚£è€…ç»Ÿè®¡å›¾å·²ä¿å­˜: {demo_plot_path}")
        
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
    
    return stats


def example_simple_training():
    """ç®€å•è®­ç»ƒç¤ºä¾‹"""
    print("\nğŸ‹ï¸ ç®€å•æ¨¡å‹è®­ç»ƒç¤ºä¾‹")
    print("=" * 50)
    
    # å®šä¹‰ç®€å•çš„åˆ†å‰²æ¨¡å‹
    class SimpleSegModel(nn.Module):
        def __init__(self, in_channels=1, num_classes=4):
            super().__init__()
            self.conv1 = nn.Conv3d(in_channels, 32, 3, padding=1)
            self.conv2 = nn.Conv3d(32, 64, 3, padding=1)
            self.conv3 = nn.Conv3d(64, num_classes, 1)
            self.pool = nn.AdaptiveAvgPool3d((8, 64, 64))
            
        def forward(self, x):
            x = torch.relu(self.conv1(x))
            x = self.pool(x)
            x = torch.relu(self.conv2(x))
            x = self.conv3(x)
            return x
    
    # åˆ›å»ºæ•°æ®
    data_root = "/Users/fenghaojie/Documents/ICLR/MedCompression/acdc_dataset"
    
    # è®­ç»ƒå˜æ¢
    train_transforms = get_train_transforms(
        output_size=(8, 64, 64),
        augmentation=True
    )
    
    # è®­ç»ƒæ•°æ®é›†
    train_dataset = ACDCDataset(
        data_root=data_root,
        split='training',
        mode='ed_only',  # åªä½¿ç”¨EDå¸§
        transform=train_transforms,
        load_segmentation=True
    )
    
    print(f"ğŸ“š è®­ç»ƒæ•°æ®é›†: {len(train_dataset)}ä¾‹")
    
    # æ•°æ®åŠ è½½å™¨ - ä½¿ç”¨ä¿å®ˆè®¾ç½®é¿å…å¤šè¿›ç¨‹é—®é¢˜
    train_loader = DataLoader(
        train_dataset,
        batch_size=1,  # ä½¿ç”¨å°æ‰¹æ¬¡
        shuffle=True,
        num_workers=0  # ä½¿ç”¨å•è¿›ç¨‹
    )
    
    # æ¨¡å‹
    model = SimpleSegModel()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    # è®­ç»ƒå‡ ä¸ªepoch
    print(f"ğŸ‹ï¸ å¼€å§‹è®­ç»ƒ...")
    model.train()
    
    for epoch in range(2):  # åªè®­ç»ƒ2ä¸ªepochä½œä¸ºç¤ºä¾‹
        total_loss = 0
        n_batches = 0
        
        for batch in train_loader:
            try:
                # æ£€æŸ¥æ•°æ®æ ¼å¼å¹¶å¤„ç†
                if 'image' in batch and 'segmentation' in batch:
                    images = batch['image']
            targets = batch['segmentation']
                    
                    # ç¡®ä¿æ­£ç¡®çš„ç»´åº¦
                    if images.dim() == 4:  # [B, D, H, W]
                        images = images.unsqueeze(1)  # [B, 1, D, H, W]
                    elif images.dim() == 3:  # [D, H, W]
                        images = images.unsqueeze(0).unsqueeze(0)  # [1, 1, D, H, W]
                        
                elif 'images' in batch and 'segmentations' in batch:
                    # å¤„ç†3d_keyframesæ¨¡å¼
                    images = batch['images']
                    targets = batch['segmentations']
                    
                    if images.dim() == 5:  # [B, T, D, H, W]
                        images = images[:, 0].unsqueeze(1)  # ä½¿ç”¨EDå¸§ [B, 1, D, H, W]
                        targets = targets[:, 0]  # EDåˆ†å‰²
                    
                else:
                    print(f"      âš ï¸ è·³è¿‡æ‰¹æ¬¡ï¼šç¼ºå°‘å¿…è¦æ•°æ®ï¼Œkeys: {list(batch.keys())}")
                    continue
            except Exception as e:
                print(f"      âš ï¸ æ•°æ®å¤„ç†å¤±è´¥: {e}")
                continue
            
            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = criterion(outputs, targets)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            n_batches += 1
            
            if n_batches >= 5:  # åªè®­ç»ƒ5ä¸ªbatchä½œä¸ºç¤ºä¾‹
                break
        
        avg_loss = total_loss / n_batches if n_batches > 0 else 0
        print(f"  Epoch {epoch+1}: Loss = {avg_loss:.4f}")
    
    print(f"âœ… è®­ç»ƒå®Œæˆ!")


def example_model_selection_and_testing():
    """ğŸ¯ æ¨¡å‹é€‰æ‹©å’Œå®Œæ•´åŠŸèƒ½æµ‹è¯•ç¤ºä¾‹"""
    print("\nğŸ¯ æ¨¡å‹é€‰æ‹©å’Œå®Œæ•´åŠŸèƒ½æµ‹è¯•ç¤ºä¾‹")
    print("=" * 60)
    
    # åˆ›å»ºä¸»è¾“å‡ºç›®å½•
    main_output_dir = create_output_directory("model_selection_testing")
    
    data_root = "/Users/fenghaojie/Documents/ICLR/MedCompression/acdc_dataset"
    
    # === 1. æµ‹è¯•æ‰€æœ‰æ•°æ®åŠ è½½æ¨¡å¼ ===
    print("\nğŸ“Š æµ‹è¯•æ‰€æœ‰æ•°æ®åŠ è½½æ¨¡å¼:")
    modes_to_test = ['3d_keyframes', 'ed_only', 'es_only']  # æš‚æ—¶ä¸æµ‹è¯•4d_sequenceä»¥èŠ‚çœæ—¶é—´
    
    for mode in modes_to_test:
        try:
            print(f"\n  ğŸ”„ æµ‹è¯•æ¨¡å¼: {mode}")
            dataset = ACDCDataset(
                data_root=data_root,
                split='training',
                mode=mode,
                load_segmentation=True,
                normalize=True
            )
            
            sample = dataset[0]
            print(f"    âœ… æ ·æœ¬æ•°: {len(dataset)}")
            print(f"    ğŸ“ æ•°æ®å½¢çŠ¶: {[f'{k}: {v.shape}' for k, v in sample.items() if isinstance(v, torch.Tensor)]}")
            
        except Exception as e:
            print(f"    âŒ æ¨¡å¼ {mode} æµ‹è¯•å¤±è´¥: {e}")
    
    # === 2. æµ‹è¯•æ‰€æœ‰å˜æ¢åŠŸèƒ½ ===
    print("\nğŸ¨ æµ‹è¯•æ‰€æœ‰æ•°æ®å˜æ¢åŠŸèƒ½:")
    from utils.transforms import (
        RandomRotation3D, RandomFlip3D, RandomNoise, 
        RandomIntensityShift, RandomScale, CenterCrop3D, 
        Pad3D, ToTensor, Compose, get_train_transforms, 
        get_val_transforms, get_test_transforms
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    test_dataset = ACDCDataset(
        data_root=data_root,
        split='training',
        mode='3d_keyframes',
        load_segmentation=True,
        normalize=False  # å…ˆä¸å½’ä¸€åŒ–ï¼Œæµ‹è¯•å˜æ¢æ•ˆæœ
    )
    
    transforms_to_test = [
        ("éšæœºæ—‹è½¬", RandomRotation3D(angle_range=15.0, probability=1.0)),
        ("éšæœºç¿»è½¬", RandomFlip3D(probability=1.0)),
        ("éšæœºå™ªå£°", RandomNoise(noise_std=0.1, probability=1.0)),
        ("å¼ºåº¦åç§»", RandomIntensityShift(shift_range=0.2, probability=1.0)),
        ("éšæœºç¼©æ”¾", RandomScale(scale_range=(0.9, 1.1), probability=1.0)),
        ("ä¸­å¿ƒè£å‰ª", CenterCrop3D(output_size=(8, 128, 128))),
        ("é›¶å¡«å……", Pad3D(output_size=(12, 256, 256))),
        ("è½¬å¼ é‡", ToTensor()),
    ]
    
    test_sample = test_dataset[0]
    print(f"    ğŸ“ åŸå§‹æ•°æ®å½¢çŠ¶: {test_sample['images'].shape}")
    
    for name, transform in transforms_to_test:
        try:
            transformed = transform(test_sample.copy())
            if 'images' in transformed:
                print(f"    âœ… {name}: {transformed['images'].shape}")
            else:
                print(f"    âœ… {name}: åº”ç”¨æˆåŠŸ")
        except Exception as e:
            print(f"    âŒ {name} æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•ç»„åˆå˜æ¢
    print(f"\n  ğŸ”„ æµ‹è¯•ç»„åˆå˜æ¢:")
    try:
        train_transforms = get_train_transforms(output_size=(8, 224, 224), augmentation=True)
        val_transforms = get_val_transforms(output_size=(8, 224, 224))
        test_transforms = get_test_transforms(output_size=(8, 224, 224))
        
        for name, transform in [("è®­ç»ƒå˜æ¢", train_transforms), ("éªŒè¯å˜æ¢", val_transforms), ("æµ‹è¯•å˜æ¢", test_transforms)]:
            transformed = transform(test_sample.copy())
            print(f"    âœ… {name}: {transformed['images'].shape}")
    except Exception as e:
        print(f"    âŒ ç»„åˆå˜æ¢æµ‹è¯•å¤±è´¥: {e}")
    
    # === 3. æµ‹è¯•æ‰€æœ‰åˆ†æåŠŸèƒ½ ===
    print("\nğŸ“ˆ æµ‹è¯•æ‰€æœ‰åˆ†æåŠŸèƒ½:")
    from utils.analysis import analyze_dataset_statistics, create_dataset_report, get_dataset_summary
    
    try:
        # ç»Ÿè®¡åˆ†æ
        stats = analyze_dataset_statistics(test_dataset)
        print(f"    âœ… æ•°æ®é›†ç»Ÿè®¡åˆ†æ: {len(stats)}é¡¹ç»Ÿè®¡ä¿¡æ¯")
        
        # ç”Ÿæˆæ‘˜è¦
        summary = get_dataset_summary(test_dataset)
        print(f"    âœ… æ•°æ®é›†æ‘˜è¦ç”Ÿæˆ: {len(summary)}å­—ç¬¦")
        
        # ç”ŸæˆæŠ¥å‘Šï¼ˆç®€åŒ–ç‰ˆï¼Œä¸å®é™…ä¿å­˜æ–‡ä»¶ï¼‰
        print(f"    âœ… æ•°æ®é›†æŠ¥å‘Šç”ŸæˆåŠŸèƒ½å¯ç”¨")
        
    except Exception as e:
        print(f"    âŒ åˆ†æåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    # === 4. æµ‹è¯•æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ ===
    print("\nğŸ’“ æµ‹è¯•æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡åŠŸèƒ½:")
    from utils.metrics import (
        calculate_cardiac_metrics, evaluate_segmentation, 
        calculate_hausdorff_distance, calculate_volume_similarity,
        evaluate_cardiac_function, assess_cardiac_health
    )
    
    try:
        # è·å–æœ‰åˆ†å‰²çš„æ ·æœ¬
        seg_sample = None
        for i in range(min(5, len(test_dataset))):
            sample = test_dataset[i]
            if 'segmentations' in sample and sample['segmentations'] is not None:
                seg_sample = sample
                break
        
        if seg_sample is not None:
            ed_seg = seg_sample['segmentations'][0].numpy()
            es_seg = seg_sample['segmentations'][1].numpy()
            spacing = seg_sample['metadata'].get('spacing', (1.5625, 1.5625, 10.0))
            
            # å¿ƒè„åŠŸèƒ½æŒ‡æ ‡
            cardiac_metrics = calculate_cardiac_metrics(ed_seg, es_seg, spacing)
            print(f"    âœ… å¿ƒè„åŠŸèƒ½æŒ‡æ ‡è®¡ç®—: LVEF={cardiac_metrics['lv_ef']:.1f}%")
            
            # åˆ†å‰²è¯„ä¼°
            seg_metrics = evaluate_segmentation(ed_seg, es_seg)  # ç”¨EDå’ŒESåšç¤ºä¾‹æ¯”è¾ƒ
            print(f"    âœ… åˆ†å‰²è¯„ä¼°: å¹³å‡Dice={seg_metrics['dice_mean']:.3f}")
            
            # ä½“ç§¯ç›¸ä¼¼æ€§
            vol_metrics = calculate_volume_similarity(ed_seg, es_seg, spacing)
            print(f"    âœ… ä½“ç§¯ç›¸ä¼¼æ€§è®¡ç®—: {len(vol_metrics)}é¡¹æŒ‡æ ‡")
            
            # å¥åº·çŠ¶æ€è¯„ä¼°
            health_assessment = assess_cardiac_health(cardiac_metrics)
            print(f"    âœ… å¥åº·çŠ¶æ€è¯„ä¼°: {health_assessment}")
            
        else:
            print(f"    âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆåˆ†å‰²æ ·æœ¬ï¼Œè·³è¿‡æŒ‡æ ‡æµ‹è¯•")
            
    except Exception as e:
        print(f"    âŒ è¯„ä¼°æŒ‡æ ‡æµ‹è¯•å¤±è´¥: {e}")
    
    # === 5. æµ‹è¯•æ‰€æœ‰å¯è§†åŒ–åŠŸèƒ½ ===
    print("\nğŸ¨ æµ‹è¯•æ‰€æœ‰å¯è§†åŒ–åŠŸèƒ½:")
    from utils.visualization import (
        plot_disease_distribution, plot_patient_demographics,
        visualize_cardiac_phases, plot_cardiac_metrics_comparison,
        plot_segmentation_overlay, plot_intensity_histogram
    )
    
    # åˆ›å»ºå¯è§†åŒ–è¾“å‡ºç›®å½•
    viz_output_dir = main_output_dir / "visualizations"
    viz_output_dir.mkdir(exist_ok=True)
    
    try:
        # ç–¾ç—…åˆ†å¸ƒå›¾
        disease_dist = test_dataset.get_disease_distribution()
        disease_plot_path = viz_output_dir / "disease_distribution_test.png"
        plot_disease_distribution(disease_dist, save_path=disease_plot_path)
        print(f"    âœ… ç–¾ç—…åˆ†å¸ƒå›¾å·²ä¿å­˜: {disease_plot_path}")
        
        # æ‚£è€…ç»Ÿè®¡å›¾
        stats = analyze_dataset_statistics(test_dataset)
        if 'patient_demographics' in stats and stats['patient_demographics']:
            demo_plot_path = viz_output_dir / "patient_demographics_test.png"
            plot_patient_demographics(stats, save_path=demo_plot_path)
            print(f"    âœ… æ‚£è€…ç»Ÿè®¡å›¾å·²ä¿å­˜: {demo_plot_path}")
        
        # å¿ƒè„æ—¶ç›¸å¯è§†åŒ– - ç›´æ¥ä¿å­˜ä¸æ˜¾ç¤º
        if seg_sample is not None:
            cardiac_viz_path = viz_output_dir / f"cardiac_phases_{seg_sample.get('patient_id', 'test')}.png"
            try:
                # è®¾ç½®matplotlibä¸ºéäº¤äº’æ¨¡å¼
                plt.ioff()
                
                # æ‰‹åŠ¨åˆ›å»ºå¿ƒè„æ—¶ç›¸å¯è§†åŒ–
                images = seg_sample['images']
                segmentations = seg_sample.get('segmentations', None)
                
                if isinstance(images, torch.Tensor):
                    images = images.numpy()
                if segmentations is not None and isinstance(segmentations, torch.Tensor):
                    segmentations = segmentations.numpy()
                
                # é€‰æ‹©ä¸­é—´åˆ‡ç‰‡
                slice_idx = images.shape[1] // 2
                
                # åˆ›å»ºå­å›¾
                n_cols = 4 if segmentations is not None else 2
                fig, axes = plt.subplots(1, n_cols, figsize=(4*n_cols, 4))
                
                if n_cols == 2:
                    axes = [axes[0], None, axes[1], None]
                
                # æ˜¾ç¤ºEDç›¸
                ed_img = images[0, slice_idx]
                axes[0].imshow(ed_img, cmap='gray')
                axes[0].set_title('ED (End-Diastolic)')
                axes[0].axis('off')
                
                if segmentations is not None:
                    ed_seg = segmentations[0, slice_idx]
                    axes[1].imshow(ed_seg, cmap='viridis')
                    axes[1].set_title('ED Segmentation')
                    axes[1].axis('off')
                
                # æ˜¾ç¤ºESç›¸
                es_img = images[1, slice_idx]
                axes[2].imshow(es_img, cmap='gray')
                axes[2].set_title('ES (End-Systolic)')
                axes[2].axis('off')
                
                if segmentations is not None:
                    es_seg = segmentations[1, slice_idx]
                    axes[3].imshow(es_seg, cmap='viridis')
                    axes[3].set_title('ES Segmentation')
                    axes[3].axis('off')
                
                # æ·»åŠ æ‚£è€…ä¿¡æ¯
                patient_info = seg_sample.get('patient_info', {})
                disease = patient_info.get('Group', 'Unknown')
                plt.suptitle(f'Patient: {seg_sample.get("patient_id", "Unknown")} | Disease: {disease} | Slice: {slice_idx}', 
                             fontsize=12)
                
                plt.tight_layout()
                plt.savefig(cardiac_viz_path, dpi=300, bbox_inches='tight')
                plt.close()
                
            except Exception as e:
                print(f"      âš ï¸ å¿ƒè„æ—¶ç›¸å¯è§†åŒ–ä¿å­˜å¤±è´¥: {e}")
            print(f"    âœ… å¿ƒè„æ—¶ç›¸å¯è§†åŒ–å·²ä¿å­˜: {cardiac_viz_path}")
        
        # å¼ºåº¦ç›´æ–¹å›¾
        if 'images' in test_sample:
            hist_path = viz_output_dir / "intensity_histogram_test.png"
            plot_intensity_histogram(test_sample['images'].numpy(), 
                                   title="æµ‹è¯•æ ·æœ¬å¼ºåº¦åˆ†å¸ƒ", 
                                   save_path=hist_path)
            print(f"    âœ… å¼ºåº¦ç›´æ–¹å›¾å·²ä¿å­˜: {hist_path}")
        
        # åˆ†å‰²ç»“æœå åŠ æ˜¾ç¤º
        if seg_sample is not None and 'images' in seg_sample and 'segmentations' in seg_sample:
            overlay_path = viz_output_dir / f"segmentation_overlay_{seg_sample.get('patient_id', 'test')}.png"
            plot_segmentation_overlay(
                seg_sample['images'][0].numpy(),  # EDå›¾åƒ
                seg_sample['segmentations'][0].numpy(),  # EDåˆ†å‰²
                save_path=overlay_path
            )
            print(f"    âœ… åˆ†å‰²å åŠ å›¾å·²ä¿å­˜: {overlay_path}")
        
    except Exception as e:
        print(f"    âŒ å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    # === 6. æ¨¡å‹é€‰æ‹©ç¤ºä¾‹ ===
    print("\nğŸ¤– æ·±åº¦å­¦ä¹ æ¨¡å‹é€‰æ‹©ç¤ºä¾‹:")
    
    # å®šä¹‰å¤šç§æ¨¡å‹æ¶æ„
    models = {
        "ç®€å•3D CNN": SimpleSegModel,
        "3D UNet": UNet3D,
        "ResNet3Dåˆ†ç±»å™¨": ResNet3DClassifier,
        "å¿ƒè„ä¸“ç”¨ç½‘ç»œ": CardiacNet
    }
    
    for model_name, model_class in models.items():
        try:
            print(f"\n  ğŸ”§ æµ‹è¯•æ¨¡å‹: {model_name}")
            
            # æ ¹æ®ä»»åŠ¡é€‰æ‹©åˆé€‚çš„æ•°æ®é…ç½®
            if "åˆ†ç±»" in model_name:
                # åˆ†ç±»ä»»åŠ¡é…ç½®
                dataset_config = {
                    'mode': 'ed_only',
                    'load_segmentation': False,
                    'target_spacing': (2.0, 2.0, 10.0)
                }
                model = model_class(in_channels=1, num_classes=5)  # 5ç§ç–¾ç—…
                task_type = "classification"
            else:
                # åˆ†å‰²ä»»åŠ¡é…ç½®
                dataset_config = {
                    'mode': '3d_keyframes', 
                    'load_segmentation': True,
                    'target_spacing': (1.5, 1.5, 8.0)
                }
                model = model_class(in_channels=1, num_classes=4)  # 4ç§åˆ†å‰²æ ‡ç­¾
                task_type = "segmentation"
            
            # åˆ›å»ºé€‚é…çš„æ•°æ®é›†
            model_dataset = ACDCDataset(
                data_root=data_root,
                split='training',
                **dataset_config,
                transform=get_train_transforms(output_size=(8, 64, 64))
            )
            
            # è·å–æ ·æœ¬æµ‹è¯•
            test_sample = model_dataset[0]
            
            if task_type == "classification":
                input_tensor = test_sample['image'].unsqueeze(0).unsqueeze(0)  # [1, 1, D, H, W]
            else:
                input_tensor = test_sample['images'][0].unsqueeze(0).unsqueeze(0)  # EDå¸§
            
            # å‰å‘ä¼ æ’­æµ‹è¯•
            model.eval()
            with torch.no_grad():
                output = model(input_tensor)
            
            print(f"    âœ… {model_name}: è¾“å…¥{input_tensor.shape} â†’ è¾“å‡º{output.shape}")
            print(f"    ğŸ“Š ä»»åŠ¡ç±»å‹: {task_type}")
            print(f"    ğŸ¯ æ•°æ®é…ç½®: {dataset_config}")
            
        except Exception as e:
            print(f"    âŒ {model_name} æµ‹è¯•å¤±è´¥: {e}")
    
    # === 7. å®Œæ•´è®­ç»ƒç®¡é“ç¤ºä¾‹ ===
    print("\nğŸ‹ï¸ å®Œæ•´è®­ç»ƒç®¡é“ç¤ºä¾‹:")
    
    # åˆ›å»ºè®­ç»ƒè¾“å‡ºç›®å½•
    training_output_dir = main_output_dir / "training_results"
    training_output_dir.mkdir(exist_ok=True)
    
    try:
        # é€‰æ‹©æœ€ä½³æ¨¡å‹å’Œé…ç½®
        best_config = {
            'model': 'UNet3D',
            'task': 'segmentation',
            'batch_size': 2,
            'learning_rate': 0.001,
            'epochs': 2  # ç¤ºä¾‹åªè®­ç»ƒ2ä¸ªepoch
        }
        
        print(f"    ğŸ¯ æœ€ä½³é…ç½®: {best_config}")
        
        # åˆ›å»ºè®­ç»ƒç®¡é“
        training_pipeline = create_training_pipeline(data_root, best_config)
        
        # è¿è¡Œè®­ç»ƒï¼ˆç®€åŒ–ç‰ˆï¼‰
        results = run_training_example(training_pipeline, max_batches=3, output_dir=training_output_dir)
        
        print(f"    âœ… è®­ç»ƒç®¡é“æµ‹è¯•å®Œæˆ: {results}")
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        results_file = training_output_dir / "training_results.txt"
        with open(results_file, 'w', encoding='utf-8') as f:
            f.write("ğŸ‹ï¸ ACDCæ•°æ®é›†è®­ç»ƒç»“æœ\n")
            f.write("=" * 30 + "\n\n")
            f.write(f"æ¨¡å‹é…ç½®: {best_config}\n\n")
            f.write("è®­ç»ƒç»“æœ:\n")
            for key, value in results.items():
                f.write(f"  {key}: {value}\n")
        
        print(f"    ğŸ’¾ è®­ç»ƒç»“æœå·²ä¿å­˜: {results_file}")
        
    except Exception as e:
        print(f"    âŒ è®­ç»ƒç®¡é“æµ‹è¯•å¤±è´¥: {e}")
    
    # === 8. ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š ===
    print(f"\nğŸ“‹ ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š:")
    
    try:
        report_file = main_output_dir / "comprehensive_test_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# ğŸ«€ ACDC DataLoader å®Œæ•´åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ\n\n")
            f.write("âœ… **å·²æµ‹è¯•åŠŸèƒ½:**\n")
            f.write("- å¤šç§æ•°æ®åŠ è½½æ¨¡å¼ (3Då…³é”®å¸§, EDå•å¸§, ESå•å¸§)\n")
            f.write("- å®Œæ•´æ•°æ®å˜æ¢åŠŸèƒ½ (æ—‹è½¬, ç¿»è½¬, å™ªå£°, ç¼©æ”¾ç­‰)\n")
            f.write("- æ•°æ®åˆ†æå·¥å…· (ç»Ÿè®¡åˆ†æ, æ‘˜è¦ç”Ÿæˆ)\n")
            f.write("- è¯„ä¼°æŒ‡æ ‡è®¡ç®— (å¿ƒè„åŠŸèƒ½æŒ‡æ ‡, åˆ†å‰²è¯„ä¼°)\n")
            f.write("- å¯è§†åŒ–å·¥å…· (ç–¾ç—…åˆ†å¸ƒ, å¿ƒè„æ—¶ç›¸, å¼ºåº¦ç›´æ–¹å›¾ç­‰)\n")
            f.write("- å¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹ (SimpleSegModel, UNet3D, ResNet3D, CardiacNet)\n")
            f.write("- å®Œæ•´è®­ç»ƒç®¡é“ (æ•°æ®åŠ è½½â†’æ¨¡å‹è®­ç»ƒâ†’ç»“æœä¿å­˜)\n\n")
            
            f.write("## ğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„\n\n")
            f.write("```\n")
            f.write(f"{main_output_dir}/\n")
            f.write("â”œâ”€â”€ visualizations/          # å¯è§†åŒ–ç»“æœ\n")
            f.write("â”‚   â”œâ”€â”€ disease_distribution_test.png\n")
            f.write("â”‚   â”œâ”€â”€ cardiac_phases_*.png\n")
            f.write("â”‚   â”œâ”€â”€ intensity_histogram_test.png\n")
            f.write("â”‚   â””â”€â”€ segmentation_overlay_*.png\n")
            f.write("â”œâ”€â”€ training_results/        # è®­ç»ƒç»“æœ\n")
            f.write("â”‚   â””â”€â”€ training_results.txt\n")
            f.write("â””â”€â”€ comprehensive_test_report.md  # æœ¬æŠ¥å‘Š\n")
            f.write("```\n\n")
            
            f.write("## ğŸ¯ å…³é”®ç‰¹æ€§\n\n")
            f.write("- **å¤šæ¨¡æ€æ”¯æŒ**: 3D/4Dæ•°æ®, å…³é”®å¸§/å®Œæ•´åºåˆ—\n")
            f.write("- **æ™ºèƒ½é¢„å¤„ç†**: è‡ªåŠ¨é‡é‡‡æ ·, å¼ºåº¦å½’ä¸€åŒ–\n")
            f.write("- **ä¸°å¯Œå˜æ¢**: åŒ»å­¦å›¾åƒä¸“ç”¨çš„3Dæ•°æ®å¢å¼º\n")
            f.write("- **å®Œæ•´è¯„ä¼°**: å¿ƒè„åŠŸèƒ½æŒ‡æ ‡, åˆ†å‰²è´¨é‡è¯„ä¼°\n")
            f.write("- **å¯è§†åŒ–**: å¤šç§å›¾è¡¨å’ŒåŠ¨ç”»ç”Ÿæˆ\n")
            f.write("- **æ¨¡å‹é›†æˆ**: æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¶æ„\n")
            f.write("- **è‡ªåŠ¨ä¿å­˜**: æ‰€æœ‰ç»“æœè‡ªåŠ¨ä¿å­˜åˆ°æŒ‡å®šç›®å½•\n\n")
            
            f.write("## ğŸ“ˆ ä½¿ç”¨å»ºè®®\n\n")
            f.write("1. **å¿«é€ŸåŸå‹**: ä½¿ç”¨ SimpleSegModel è¿›è¡Œå¿«é€ŸéªŒè¯\n")
            f.write("2. **ç²¾ç¡®åˆ†å‰²**: ä½¿ç”¨ UNet3D è·å¾—æœ€ä½³åˆ†å‰²æ•ˆæœ\n")
            f.write("3. **ç–¾ç—…åˆ†ç±»**: ä½¿ç”¨ ResNet3DClassifier è¿›è¡Œè¯Šæ–­\n")
            f.write("4. **å¤šä»»åŠ¡å­¦ä¹ **: ä½¿ç”¨ CardiacNet åŒæ—¶è¿›è¡Œåˆ†å‰²å’Œåˆ†ç±»\n\n")
            
            f.write("## ğŸ”§ æŠ€æœ¯è¦æ±‚\n\n")
            f.write("- Python 3.8+\n")
            f.write("- PyTorch 1.8+\n")
            f.write("- æ¨èä¾èµ–: imageio (ç”¨äºGIFç”Ÿæˆ)\n")
            f.write("- GPU: å»ºè®®ç”¨äºå¤§æ¨¡å‹è®­ç»ƒ\n\n")
            
            f.write("---\n")
            f.write("*æ­¤æŠ¥å‘Šç”± ACDC DataLoader è‡ªåŠ¨ç”Ÿæˆ*\n")
        
        print(f"    ğŸ“ ç»¼åˆæµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        
    except Exception as e:
        print(f"    âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    print(f"\nğŸ‰ æ¨¡å‹é€‰æ‹©å’ŒåŠŸèƒ½æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰è¾“å‡ºå·²ä¿å­˜åˆ°: {main_output_dir}")
    
    return main_output_dir


def create_training_pipeline(data_root: str, config: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ›å»ºè®­ç»ƒç®¡é“"""
    
    # æ•°æ®æ¨¡å— - ä½¿ç”¨å•è¿›ç¨‹é¿å…å¤šè¿›ç¨‹é—®é¢˜
    data_module = ACDCDataModule(
        data_root=data_root,
        batch_size=1,  # å¼ºåˆ¶ä½¿ç”¨batch_size=1
        num_workers=0,  # ä½¿ç”¨å•è¿›ç¨‹
        mode='3d_keyframes' if config['task'] == 'segmentation' else 'ed_only',
        target_spacing=(1.5, 1.5, 8.0),
        normalize=True
    )
    data_module.setup()
    
    # æ¨¡å‹
    if config['model'] == 'UNet3D':
        model = UNet3D(in_channels=1, num_classes=4)
    else:
        model = SimpleSegModel(in_channels=1, num_classes=4)
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    if config['task'] == 'segmentation':
        criterion = nn.CrossEntropyLoss()
    else:
        criterion = nn.CrossEntropyLoss()
    
    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])
    
    return {
        'model': model,
        'data_module': data_module,
        'criterion': criterion,
        'optimizer': optimizer,
        'config': config
    }


def run_training_example(pipeline: Dict[str, Any], max_batches: int = 3, output_dir: Path = None) -> Dict[str, float]:
    """è¿è¡Œè®­ç»ƒç¤ºä¾‹"""
    
    model = pipeline['model']
    data_module = pipeline['data_module']
    criterion = pipeline['criterion'] 
    optimizer = pipeline['optimizer']
    config = pipeline['config']
    
    model.train()
    train_loader = data_module.train_dataloader()
    
    total_loss = 0.0
    batch_count = 0
    
    print(f"    ğŸ‹ï¸ å¼€å§‹è®­ç»ƒ...")
    
    for epoch in range(config['epochs']):
        epoch_loss = 0.0
        epoch_batches = 0
        
        for batch_idx, batch in enumerate(train_loader):
            if batch_idx >= max_batches:
                break
            
            try:
                # å‡†å¤‡æ•°æ®
                if config['task'] == 'segmentation':
                    if 'images' in batch:
                        # å¤„ç†batch_size=1çš„æƒ…å†µ
                        images = batch['images']
                        if images.dim() == 5:  # [B, T, D, H, W]
                            images = images[:, 0].unsqueeze(1)  # ä½¿ç”¨EDå¸§ [B, 1, D, H, W] 
                        elif images.dim() == 4:  # [B, D, H, W]
                            images = images.unsqueeze(1)  # [B, 1, D, H, W]
                        
                        if 'segmentations' in batch:
                            targets = batch['segmentations']
                            if targets.dim() == 5:  # [B, T, D, H, W]
                                targets = targets[:, 0]  # EDåˆ†å‰² [B, D, H, W]
                        else:
                            continue
                    else:
                        continue
                else:
                    if 'image' in batch:
                        images = batch['image'].unsqueeze(1)
                        targets = batch.get('disease_label', torch.zeros(images.size(0), dtype=torch.long))
                    else:
                        continue
                
                # å‰å‘ä¼ æ’­
                outputs = model(images)
                loss = criterion(outputs, targets)
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                epoch_batches += 1
                
                print(f"      Epoch {epoch+1}, Batch {batch_idx+1}: Loss = {loss.item():.4f}")
                
            except Exception as e:
                print(f"      âš ï¸ Batch {batch_idx+1} è·³è¿‡: {e}")
                continue
        
        if epoch_batches > 0:
            avg_epoch_loss = epoch_loss / epoch_batches
            total_loss += avg_epoch_loss
            batch_count += 1
            print(f"    ğŸ“Š Epoch {epoch+1} å¹³å‡æŸå¤±: {avg_epoch_loss:.4f}")
    
    final_loss = total_loss / batch_count if batch_count > 0 else 0.0
    
    # ä¿å­˜è®­ç»ƒæ—¥å¿—
    if output_dir is not None:
        log_file = output_dir / "training_log.txt"
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"ğŸ‹ï¸ è®­ç»ƒæ—¥å¿— - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ¨¡å‹: {config.get('model', 'Unknown')}\n")
            f.write(f"ä»»åŠ¡: {config.get('task', 'Unknown')}\n")
            f.write(f"æ‰¹æ¬¡å¤§å°: {config.get('batch_size', 'Unknown')}\n")
            f.write(f"å­¦ä¹ ç‡: {config.get('learning_rate', 'Unknown')}\n")
            f.write(f"è®­ç»ƒè½®æ•°: {config.get('epochs', 'Unknown')}\n")
            f.write(f"æ¯è½®æ‰¹æ¬¡æ•°: {max_batches}\n\n")
            f.write(f"æœ€ç»ˆæŸå¤±: {final_loss:.6f}\n")
        
        print(f"    ğŸ’¾ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {log_file}")
    
    return {
        'final_loss': final_loss,
        'epochs_completed': config['epochs'],
        'batches_per_epoch': max_batches
    }


# === æ¨¡å‹å®šä¹‰ ===

class UNet3D(nn.Module):
    """3D UNetåˆ†å‰²æ¨¡å‹"""
    
    def __init__(self, in_channels=1, num_classes=4, base_features=32):
        super().__init__()
        
        # ç¼–ç å™¨
        self.encoder1 = self._conv_block(in_channels, base_features)
        self.encoder2 = self._conv_block(base_features, base_features * 2)
        self.encoder3 = self._conv_block(base_features * 2, base_features * 4)
        
        # æ± åŒ–
        self.pool = nn.MaxPool3d(2)
        
        # ç“¶é¢ˆå±‚
        self.bottleneck = self._conv_block(base_features * 4, base_features * 8)
        
        # è§£ç å™¨
        self.decoder3 = self._conv_block(base_features * 12, base_features * 4)
        self.decoder2 = self._conv_block(base_features * 6, base_features * 2)
        self.decoder1 = self._conv_block(base_features * 3, base_features)
        
        # ä¸Šé‡‡æ ·
        self.upconv3 = nn.ConvTranspose3d(base_features * 8, base_features * 4, 2, 2)
        self.upconv2 = nn.ConvTranspose3d(base_features * 4, base_features * 2, 2, 2)
        self.upconv1 = nn.ConvTranspose3d(base_features * 2, base_features, 2, 2)
        
        # è¾“å‡ºå±‚
        self.output = nn.Conv3d(base_features, num_classes, 1)
        
    def _conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv3d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv3d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # ç¼–ç 
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(self.pool(enc1))
        enc3 = self.encoder3(self.pool(enc2))
        
        # ç“¶é¢ˆ
        bottleneck = self.bottleneck(self.pool(enc3))
        
        # è§£ç 
        dec3 = self.upconv3(bottleneck)
        dec3 = torch.cat([dec3, enc3], dim=1)
        dec3 = self.decoder3(dec3)
        
        dec2 = self.upconv2(dec3)
        dec2 = torch.cat([dec2, enc2], dim=1)
        dec2 = self.decoder2(dec2)
        
        dec1 = self.upconv1(dec2)
        dec1 = torch.cat([dec1, enc1], dim=1)
        dec1 = self.decoder1(dec1)
        
        return self.output(dec1)


class ResNet3DClassifier(nn.Module):
    """3D ResNetåˆ†ç±»æ¨¡å‹"""
    
    def __init__(self, in_channels=1, num_classes=5):
        super().__init__()
        
        self.conv1 = nn.Conv3d(in_channels, 64, 7, stride=2, padding=3)
        self.bn1 = nn.BatchNorm3d(64)
        self.relu = nn.ReLU(inplace=True)
        self.pool = nn.MaxPool3d(3, stride=2, padding=1)
        
        # ResNetå—
        self.layer1 = self._make_layer(64, 64, 2)
        self.layer2 = self._make_layer(64, 128, 2, stride=2)
        self.layer3 = self._make_layer(128, 256, 2, stride=2)
        
        # å…¨å±€å¹³å‡æ± åŒ–å’Œåˆ†ç±»å¤´
        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))
        self.fc = nn.Linear(256, num_classes)
        
    def _make_layer(self, in_channels, out_channels, blocks, stride=1):
        layers = []
        
        # ç¬¬ä¸€ä¸ªå—å¯èƒ½æœ‰æ­¥é•¿
        layers.append(self._basic_block(in_channels, out_channels, stride))
        
        # åç»­å—
        for _ in range(1, blocks):
            layers.append(self._basic_block(out_channels, out_channels))
        
        return nn.Sequential(*layers)
    
    def _basic_block(self, in_channels, out_channels, stride=1):
        return nn.Sequential(
            nn.Conv3d(in_channels, out_channels, 3, stride=stride, padding=1),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv3d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.pool(x)
        
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        
        return x


class CardiacNet(nn.Module):
    """å¿ƒè„ä¸“ç”¨ç½‘ç»œ - ç»“åˆåˆ†å‰²å’Œåˆ†ç±»"""
    
    def __init__(self, in_channels=1, num_classes=4, num_diseases=5):
        super().__init__()
        
        # å…±äº«ç‰¹å¾æå–å™¨
        self.feature_extractor = nn.Sequential(
            nn.Conv3d(in_channels, 32, 3, padding=1),
            nn.BatchNorm3d(32),
            nn.ReLU(inplace=True),
            nn.Conv3d(32, 64, 3, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(2)
        )
        
        # åˆ†å‰²åˆ†æ”¯
        self.seg_branch = nn.Sequential(
            nn.Conv3d(64, 128, 3, padding=1),
            nn.BatchNorm3d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose3d(128, 64, 2, 2),
            nn.Conv3d(64, num_classes, 1)
        )
        
        # åˆ†ç±»åˆ†æ”¯
        self.cls_branch = nn.Sequential(
            nn.AdaptiveAvgPool3d((1, 1, 1)),
            nn.Flatten(),
            nn.Linear(64, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(128, num_diseases)
        )
        
    def forward(self, x):
        features = self.feature_extractor(x)
        
        seg_output = self.seg_branch(features)
        cls_output = self.cls_branch(features)
        
        return seg_output, cls_output


def debug_basic_functionality():
    """è°ƒè¯•åŸºæœ¬åŠŸèƒ½ - å¿«é€Ÿæµ‹è¯•æ•°æ®åŠ è½½æ˜¯å¦æ­£å¸¸"""
    print("\nğŸ”§ è°ƒè¯•åŸºæœ¬åŠŸèƒ½")
    print("=" * 50)
    
    data_root = "/Users/fenghaojie/Documents/ICLR/MedCompression/acdc_dataset"
    
    try:
        # æµ‹è¯•æœ€åŸºæœ¬çš„æ•°æ®åŠ è½½
        print("ğŸ” æµ‹è¯•åŸºæœ¬æ•°æ®åŠ è½½...")
        with SuppressSTDERR():
            dataset = ACDCDataset(
                data_root=data_root,
                split='training',
                mode='3d_keyframes',
                load_segmentation=True,
                normalize=True
            )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ: {len(dataset)}ä¾‹æ‚£è€…")
        
        # æµ‹è¯•è·å–å•ä¸ªæ ·æœ¬
        print("ğŸ” æµ‹è¯•æ ·æœ¬è·å–...")
        with SuppressSTDERR():
            sample = dataset[0]
        print(f"âœ… æ ·æœ¬è·å–æˆåŠŸï¼ŒåŒ…å«keys: {list(sample.keys())}")
        
        # æµ‹è¯•æ•°æ®å½¢çŠ¶
        for key, value in sample.items():
            if isinstance(value, torch.Tensor):
                print(f"  ğŸ“ {key}: {value.shape} ({value.dtype})")
            elif isinstance(value, dict):
                print(f"  ğŸ“‹ {key}: {list(value.keys())}")
            else:
                print(f"  ğŸ“„ {key}: {type(value).__name__}")
        
        # æµ‹è¯•å•æ ·æœ¬DataLoader
        print("ğŸ” æµ‹è¯•å•æ ·æœ¬DataLoader...")
        from torch.utils.data import DataLoader
        test_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)
        
        with SuppressSTDERR():
            for i, batch in enumerate(test_loader):
                print(f"âœ… æ‰¹æ¬¡ {i} åŠ è½½æˆåŠŸ")
                for key, value in batch.items():
                    if isinstance(value, torch.Tensor):
                        print(f"  ğŸ“ æ‰¹æ¬¡ {key}: {value.shape}")
                break  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
        
        print("ğŸ‰ åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return False


def display_menu():
    """æ˜¾ç¤ºåŠŸèƒ½é€‰æ‹©èœå•"""
    print("\nğŸ«€ ACDCæ•°æ®é›†åŠ è½½å™¨ - åŠŸèƒ½é€‰æ‹©èœå•")
    print("=" * 60)
    print("ğŸ“‹ å¯ç”¨åŠŸèƒ½:")
    print("  1ï¸âƒ£  åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("     â””â”€ æ•°æ®åŠ è½½ + å¿ƒè„æ—¶ç›¸å¯è§†åŒ– + å›¾åƒä¿å­˜")
    print("  2ï¸âƒ£  æ•°æ®æ¨¡å—ä½¿ç”¨ç¤ºä¾‹") 
    print("     â””â”€ æ‰¹é‡æ•°æ®åŠ è½½ + DataLoaderæµ‹è¯•")
    print("  3ï¸âƒ£  æ•°æ®å˜æ¢ç¤ºä¾‹")
    print("     â””â”€ 3DåŒ»å­¦å›¾åƒå¢å¼ºå˜æ¢æµ‹è¯•")
    print("  4ï¸âƒ£  4Dæ—¶åºæ•°æ®ç¤ºä¾‹")
    print("     â””â”€ å¿ƒè·³åŠ¨ç”»ç”Ÿæˆ + GIFè§†é¢‘ä¿å­˜")
    print("  5ï¸âƒ£  å¿ƒè„åŠŸèƒ½æŒ‡æ ‡è®¡ç®—ç¤ºä¾‹")
    print("     â””â”€ LVEF, RVEFç­‰ä¸´åºŠæŒ‡æ ‡è®¡ç®—")
    print("  6ï¸âƒ£  æ•°æ®é›†åˆ†æç¤ºä¾‹")
    print("     â””â”€ ç»Ÿè®¡æŠ¥å‘Š + ç–¾ç—…åˆ†å¸ƒå›¾è¡¨ + MarkdownæŠ¥å‘Š")
    print("  7ï¸âƒ£  ç®€å•è®­ç»ƒç¤ºä¾‹")
    print("     â””â”€ åŸºç¡€3D CNNæ¨¡å‹è®­ç»ƒæ¼”ç¤º")
    print("  8ï¸âƒ£  ğŸŒŸ æ¨¡å‹é€‰æ‹©å’Œå®Œæ•´åŠŸèƒ½æµ‹è¯•")
    print("     â””â”€ æ‰€æœ‰åŠŸèƒ½æµ‹è¯• + å¤šæ¨¡å‹å¯¹æ¯” + å®Œæ•´ç»“æœä¿å­˜")
    print("  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("  ğŸ”§ D  è°ƒè¯•åŸºæœ¬åŠŸèƒ½ (å¿«é€Ÿé—®é¢˜è¯Šæ–­)")
    print("  ğŸ”„ A  è¿è¡Œæ‰€æœ‰ç¤ºä¾‹ (æ¨èæ–°ç”¨æˆ·)")
    print("  ğŸ’¡ H  æ˜¾ç¤ºè¯¦ç»†å¸®åŠ©ä¿¡æ¯")
    print("  âŒ Q  é€€å‡ºç¨‹åº")
    print("=" * 60)


def display_help():
    """æ˜¾ç¤ºè¯¦ç»†å¸®åŠ©ä¿¡æ¯"""
    print("\nğŸ“– ACDCæ•°æ®é›†åŠ è½½å™¨ - è¯¦ç»†å¸®åŠ©")
    print("=" * 60)
    print("ğŸ¯ åŠŸèƒ½è¯¦ç»†è¯´æ˜:")
    print()
    
    help_info = [
        ("1ï¸âƒ£ åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹", [
            "â€¢ åŠ è½½ACDCæ•°æ®é›†ï¼ˆ3Då…³é”®å¸§æ¨¡å¼ï¼‰",
            "â€¢ æ˜¾ç¤ºæ ·æœ¬ä¿¡æ¯å’Œæ•°æ®å½¢çŠ¶",
            "â€¢ ç”Ÿæˆå¿ƒè„ED/ESæ—¶ç›¸å¯è§†åŒ–å›¾åƒ",
            "â€¢ è‡ªåŠ¨ä¿å­˜å¯è§†åŒ–ç»“æœåˆ°PNGæ–‡ä»¶",
            "â±ï¸ é¢„è®¡æ—¶é—´: ~30ç§’"
        ]),
        ("2ï¸âƒ£ æ•°æ®æ¨¡å—ä½¿ç”¨ç¤ºä¾‹", [
            "â€¢ æµ‹è¯•ACDCDataModuleæ•°æ®åŠ è½½å™¨",
            "â€¢ æ‰¹é‡æ•°æ®å¤„ç†å’Œç»Ÿè®¡ä¿¡æ¯",
            "â€¢ DataLoaderå¤šè¿›ç¨‹åŠ è½½æµ‹è¯•",
            "â±ï¸ é¢„è®¡æ—¶é—´: ~20ç§’"
        ]),
        ("3ï¸âƒ£ æ•°æ®å˜æ¢ç¤ºä¾‹", [
            "â€¢ æµ‹è¯•8ç§3DåŒ»å­¦å›¾åƒå˜æ¢",
            "â€¢ æ—‹è½¬ã€ç¿»è½¬ã€å™ªå£°ã€ç¼©æ”¾ç­‰å¢å¼º",
            "â€¢ ç»„åˆå˜æ¢ç®¡é“æµ‹è¯•",
            "â±ï¸ é¢„è®¡æ—¶é—´: ~15ç§’"
        ]),
        ("4ï¸âƒ£ 4Dæ—¶åºæ•°æ®ç¤ºä¾‹", [
            "â€¢ åŠ è½½å®Œæ•´å¿ƒè·³å‘¨æœŸ4Dæ•°æ®",
            "â€¢ ç”Ÿæˆå¿ƒè·³åŠ¨ç”»å…³é”®å¸§",
            "â€¢ åˆ›å»ºå¹¶ä¿å­˜å¿ƒè·³GIFåŠ¨ç”»",
            "ğŸ“¦ éœ€è¦: imageioåº“ (pip install imageio)",
            "â±ï¸ é¢„è®¡æ—¶é—´: ~45ç§’"
        ]),
        ("5ï¸âƒ£ å¿ƒè„åŠŸèƒ½æŒ‡æ ‡è®¡ç®—", [
            "â€¢ è®¡ç®—LVEFã€RVEFå°„è¡€åˆ†æ•°",
            "â€¢ è®¡ç®—å¿ƒå®¤å®¹ç§¯å’Œå¿ƒè‚Œè´¨é‡",
            "â€¢ è‡ªåŠ¨å¿ƒåŠŸèƒ½çŠ¶æ€è¯„ä¼°",
            "â±ï¸ é¢„è®¡æ—¶é—´: ~20ç§’"
        ]),
        ("6ï¸âƒ£ æ•°æ®é›†åˆ†æç¤ºä¾‹", [
            "â€¢ ç”Ÿæˆå®Œæ•´æ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š",
            "â€¢ ç–¾ç—…åˆ†å¸ƒå’Œæ‚£è€…ç»Ÿè®¡å›¾è¡¨",
            "â€¢ ä¿å­˜Markdownåˆ†ææŠ¥å‘Š",
            "â€¢ ç”Ÿæˆå¤šç§å¯è§†åŒ–å›¾è¡¨",
            "â±ï¸ é¢„è®¡æ—¶é—´: ~40ç§’"
        ]),
        ("7ï¸âƒ£ ç®€å•è®­ç»ƒç¤ºä¾‹", [
            "â€¢ 3D CNNåˆ†å‰²æ¨¡å‹è®­ç»ƒæ¼”ç¤º",
            "â€¢ æ•°æ®åŠ è½½å’Œè®­ç»ƒç®¡é“æµ‹è¯•",
            "â€¢ æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨é…ç½®",
            "â±ï¸ é¢„è®¡æ—¶é—´: ~60ç§’"
        ]),
        ("8ï¸âƒ£ å®Œæ•´åŠŸèƒ½æµ‹è¯•", [
            "â€¢ æµ‹è¯•æ‰€æœ‰æ•°æ®åŠ è½½æ¨¡å¼",
            "â€¢ æµ‹è¯•æ‰€æœ‰å˜æ¢å’Œåˆ†æå·¥å…·",
            "â€¢ 4ç§æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹æ¯”æµ‹è¯•",
            "â€¢ å®Œæ•´è®­ç»ƒç®¡é“æ¼”ç¤º",
            "â€¢ ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š",
            "â€¢ æ‰€æœ‰ç»“æœè‡ªåŠ¨ä¿å­˜",
            "â±ï¸ é¢„è®¡æ—¶é—´: ~3-5åˆ†é’Ÿ"
        ])
    ]
    
    for title, items in help_info:
        print(f"{title}:")
        for item in items:
            print(f"    {item}")
        print()
    
    print("ğŸ’¾ è¾“å‡ºæ–‡ä»¶è¯´æ˜:")
    print("  â€¢ æ‰€æœ‰ç»“æœä¿å­˜åœ¨ output/acdc_results_[æ—¶é—´æˆ³]/ ç›®å½•")
    print("  â€¢ åŒ…å«å¯è§†åŒ–å›¾åƒã€è®­ç»ƒæ—¥å¿—ã€åˆ†ææŠ¥å‘Šç­‰")
    print("  â€¢ æ”¯æŒPNGå›¾åƒã€GIFåŠ¨ç”»ã€MarkdownæŠ¥å‘Šæ ¼å¼")
    print()
    
    print("âš ï¸ è¿è¡Œè¦æ±‚:")
    print("  â€¢ ç¡®ä¿ACDCæ•°æ®é›†è·¯å¾„æ­£ç¡®")
    print("  â€¢ å®‰è£…æ‰€éœ€ä¾èµ–: torch, numpy, matplotlib, SimpleITK")
    print("  â€¢ å¯é€‰ä¾èµ–: imageio (ç”¨äºGIFç”Ÿæˆ)")
    print("  â€¢ å»ºè®®GPUç¯å¢ƒï¼ˆç”¨äºæ¨¡å‹è®­ç»ƒï¼‰")
    print("=" * 60)


def get_user_choice():
    """è·å–ç”¨æˆ·é€‰æ‹©"""
    while True:
        choice = input("ğŸ¯ è¯·è¾“å…¥æ‚¨çš„é€‰æ‹© (1-8, D, A, H, Q): ").strip().upper()
        if choice in ['1', '2', '3', '4', '5', '6', '7', '8', 'D', 'A', 'H', 'Q']:
            return choice
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-8, D, A, H æˆ– Q")


def show_progress_bar(progress: float, total_width: int = 40):
    """æ˜¾ç¤ºè¿›åº¦æ¡"""
    filled_width = int(total_width * progress)
    bar = 'â–ˆ' * filled_width + 'â–’' * (total_width - filled_width)
    percentage = progress * 100
    return f"[{bar}] {percentage:.1f}%"


def run_selected_function(choice: str):
    """è¿è¡Œé€‰å®šçš„åŠŸèƒ½"""
    functions = {
        '1': ('åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹', example_basic_usage),
        '2': ('æ•°æ®æ¨¡å—ä½¿ç”¨ç¤ºä¾‹', example_data_module),
        '3': ('æ•°æ®å˜æ¢ç¤ºä¾‹', example_with_transforms),
        '4': ('4Dæ—¶åºæ•°æ®ç¤ºä¾‹', example_4d_sequence),
        '5': ('å¿ƒè„åŠŸèƒ½æŒ‡æ ‡è®¡ç®—ç¤ºä¾‹', example_cardiac_metrics),
        '6': ('æ•°æ®é›†åˆ†æç¤ºä¾‹', example_dataset_analysis),
        '7': ('ç®€å•è®­ç»ƒç¤ºä¾‹', example_simple_training),
        '8': ('æ¨¡å‹é€‰æ‹©å’Œå®Œæ•´åŠŸèƒ½æµ‹è¯•', example_model_selection_and_testing),
        'D': ('è°ƒè¯•åŸºæœ¬åŠŸèƒ½', debug_basic_functionality),
    }
    
    if choice in functions:
        name, func = functions[choice]
        print(f"\nğŸš€ æ‰§è¡Œ: {name}")
        print("=" * 50)
        
        # æ˜¾ç¤ºå¼€å§‹æ—¶é—´
        start_time = datetime.now()
        print(f"â° å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}")
        
        try:
            print(f"ğŸ”„ æ­£åœ¨æ‰§è¡Œ...")
            result = func()
            
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            print(f"\nâœ… {name} å®Œæˆ!")
            print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {duration:.1f}ç§’")
            print(f"ğŸ å®Œæˆæ—¶é—´: {end_time.strftime('%H:%M:%S')}")
            
            # å¦‚æœæœ‰è¿”å›å€¼ï¼ˆè¾“å‡ºç›®å½•ï¼‰ï¼Œæ˜¾ç¤ºç»“æœè·¯å¾„
            if hasattr(result, '__fspath__') or isinstance(result, (str, Path)):
                print(f"ğŸ“ è¾“å‡ºä¿å­˜åˆ°: {result}")
                # å°è¯•æ˜¾ç¤ºè¾“å‡ºç›®å½•å†…å®¹
                try:
                    output_path = Path(result)
                    if output_path.exists():
                        files = list(output_path.rglob('*'))
                        if files:
                            print(f"ğŸ“„ ç”Ÿæˆäº† {len(files)} ä¸ªæ–‡ä»¶:")
                            # æ˜¾ç¤ºå‰å‡ ä¸ªä¸»è¦æ–‡ä»¶
                            for i, file in enumerate(files[:5]):
                                if file.is_file():
                                    size = file.stat().st_size
                                    if size > 1024:
                                        size_str = f"{size/1024:.1f}KB"
                                    else:
                                        size_str = f"{size}B"
                                    print(f"  ğŸ“ {file.name} ({size_str})")
                            if len(files) > 5:
                                print(f"  ğŸ“ ... è¿˜æœ‰ {len(files)-5} ä¸ªæ–‡ä»¶")
                except Exception:
                    pass
                
        except Exception as e:
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            print(f"\nâŒ {name} æ‰§è¡Œå¤±è´¥: {e}")
            print(f"â±ï¸ å¤±è´¥å‰è¿è¡Œæ—¶é—´: {duration:.1f}ç§’")
        print("ğŸ’¡ è¯·ç¡®ä¿:")
        print("  1. æ•°æ®è·¯å¾„æ­£ç¡®")
        print("  2. å·²å®‰è£…æ‰€æœ‰ä¾èµ–")
        print("  3. æ•°æ®é›†å·²æ­£ç¡®ä¸‹è½½")
        print("  4. æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´")
        print("  5. æƒé™è®¾ç½®æ­£ç¡®")


def run_all_examples():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹ï¼ˆè‡ªåŠ¨æ¨¡å¼ï¼‰"""
    print("\nğŸ”„ è‡ªåŠ¨è¿è¡Œæ‰€æœ‰ç¤ºä¾‹")
    print("=" * 60)
    
    # å®šä¹‰è¦è¿è¡Œçš„ç¤ºä¾‹åˆ—è¡¨ï¼ˆæŒ‰æ¨èé¡ºåºï¼‰
    examples = [
        ('1', 'åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹'),
        ('2', 'æ•°æ®æ¨¡å—ä½¿ç”¨ç¤ºä¾‹'),
        ('3', 'æ•°æ®å˜æ¢ç¤ºä¾‹'),
        ('5', 'å¿ƒè„åŠŸèƒ½æŒ‡æ ‡è®¡ç®—ç¤ºä¾‹'),
        ('6', 'æ•°æ®é›†åˆ†æç¤ºä¾‹'),
        ('8', 'æ¨¡å‹é€‰æ‹©å’Œå®Œæ•´åŠŸèƒ½æµ‹è¯•'),
    ]
    
    completed = []
    failed = []
    total_examples = len(examples)
    start_time = datetime.now()
    
    print(f"ğŸ“‹ è®¡åˆ’æ‰§è¡Œ {total_examples} ä¸ªç¤ºä¾‹")
    print(f"â° å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}")
    
    for i, (choice, name) in enumerate(examples, 1):
        # æ˜¾ç¤ºæ€»ä½“è¿›åº¦
        progress = (i - 1) / total_examples
        progress_bar = show_progress_bar(progress, 30)
        print(f"\n{progress_bar} ({i}/{total_examples})")
        print(f"ğŸ“ å½“å‰æ‰§è¡Œ: {name}")
        print("-" * 30)
        
        try:
            run_selected_function(choice)
            completed.append(name)
            print(f"âœ… {name} - æˆåŠŸ")
        except Exception as e:
            print(f"âŒ {name} å¤±è´¥: {e}")
            failed.append(name)
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­
            continue_choice = input(f"\nâš ï¸ {name} æ‰§è¡Œå¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­æ‰§è¡Œå‰©ä½™ç¤ºä¾‹? (Y/n): ").strip().upper()
            if continue_choice in ['N', 'NO']:
                print("ğŸ›‘ ç”¨æˆ·é€‰æ‹©åœæ­¢æ‰§è¡Œ")
                break
    
    # å®Œæˆè¿›åº¦æ¡
    final_progress_bar = show_progress_bar(1.0, 30)
    print(f"\n{final_progress_bar} (å®Œæˆ)")
    
    # è®¡ç®—æ€»æ—¶é—´
    end_time = datetime.now()
    total_duration = (end_time - start_time).total_seconds()
    
    # æ€»ç»“
    print(f"\nğŸ“Š æ‰§è¡Œæ€»ç»“:")
    print(f"â±ï¸ æ€»è€—æ—¶: {total_duration/60:.1f}åˆ†é’Ÿ ({total_duration:.1f}ç§’)")
    print(f"âœ… æˆåŠŸå®Œæˆ: {len(completed)}ä¸ª")
    for name in completed:
        print(f"  âœ“ {name}")
    
    if failed:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {len(failed)}ä¸ª")
        for name in failed:
            print(f"  âœ— {name}")
    
    success_rate = len(completed) / total_examples * 100
    print(f"\nğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
    print(f"ğŸ‰ è‡ªåŠ¨æ‰§è¡Œå®Œæˆ!")


def setup_silent_environment():
    """è®¾ç½®é™é»˜ç¯å¢ƒï¼ŒæŠ‘åˆ¶å„ç§è­¦å‘Š"""
    # è®¾ç½®ITK/SimpleITKç¯å¢ƒå˜é‡
    os.environ['ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS'] = '1'
    os.environ['SITK_SHOW_COMMAND'] = ''
    os.environ['ITK_USE_THREADPOOL'] = '0'
    
    # å°è¯•è®¾ç½®SimpleITKæ—¥å¿—çº§åˆ«
    try:
        import SimpleITK as sitk
        # è®¾ç½®SimpleITKé™é»˜æ¨¡å¼
        sitk.ProcessObject_SetGlobalWarningDisplay(False)
    except:
        pass


def main():
    """ä¸»å‡½æ•° - äº¤äº’å¼èœå•"""
    # è®¾ç½®é™é»˜ç¯å¢ƒ
    setup_silent_environment()
    
    # è®¾ç½®matplotlibä¸ºéäº¤äº’æ¨¡å¼ï¼Œé¿å…å¼¹å‡ºå›¾å½¢çª—å£
    plt.ioff()
    import matplotlib
    matplotlib.use('Agg')  # ä½¿ç”¨æ— GUIåç«¯
    
    # è®¾ç½®matplotlibå­—ä½“ï¼Œé¿å…ä¸­æ–‡å­—ä½“è­¦å‘Š
    try:
        import matplotlib.font_manager as fm
        # å°è¯•è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨è‹±æ–‡
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
    except:
        # å¦‚æœä¸­æ–‡å­—ä½“è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨è‹±æ–‡æ ‡é¢˜
        pass
    
    print("ğŸ«€ æ¬¢è¿ä½¿ç”¨ ACDC å¿ƒè„MRIæ•°æ®é›†åŠ è½½å™¨!")
    print("ğŸ“ å·²è®¾ç½®ä¸ºé™é»˜æ¨¡å¼ - æ‰€æœ‰å›¾åƒå°†ç›´æ¥ä¿å­˜ï¼Œä¸æ˜¾ç¤º")
    print("ğŸ”‡ å·²æŠ‘åˆ¶æ‰€æœ‰è­¦å‘Šä¿¡æ¯")
    
    while True:
        display_menu()
        choice = get_user_choice()
        
        if choice == 'Q':
            print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§!")
            break
        elif choice == 'A':
            run_all_examples()
            print("\nğŸ”„ è¿”å›ä¸»èœå•...")
        elif choice == 'H':
            display_help()
            input("\nğŸ“– æŒ‰ Enter é”®è¿”å›ä¸»èœå•...")
        elif choice == 'D':
            # è°ƒè¯•åŠŸèƒ½ - ç‰¹æ®Šå¤„ç†
            print("\nğŸ”§ å¼€å§‹è°ƒè¯•åŸºæœ¬åŠŸèƒ½...")
            success = debug_basic_functionality()
            if success:
                print("\nâœ… è°ƒè¯•å®Œæˆ - åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
            else:
                print("\nâŒ è°ƒè¯•å‘ç°é—®é¢˜ - è¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œç¯å¢ƒé…ç½®")
            input("\nğŸ”™ æŒ‰ Enter é”®è¿”å›ä¸»èœå•...")
        else:
            run_selected_function(choice)
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­
            print("\n" + "=" * 60)
            continue_choice = input("ğŸ”„ æ˜¯å¦ç»§ç»­ä½¿ç”¨å…¶ä»–åŠŸèƒ½? (Y/n): ").strip().upper()
            if continue_choice in ['N', 'NO']:
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§!")
                break


if __name__ == "__main__":
    # å®Œå…¨æŠ‘åˆ¶stderrä»¥æ¶ˆé™¤æ‰€æœ‰C++å±‚é¢çš„è­¦å‘Š
    import os
    import sys
    
    # ä¿å­˜åŸå§‹stderr
    original_stderr = sys.stderr
    
    try:
        # é‡å®šå‘stderråˆ°ç©ºè®¾å¤‡
        sys.stderr = open(os.devnull, 'w')
        
        # è¿è¡Œä¸»ç¨‹åº
    main()
        
    finally:
        # æ¢å¤stderr
        sys.stderr.close()
        sys.stderr = original_stderr
